{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chart_2_text_reduced.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "B92qnMW1Oqmi",
        "T1XNOGTxJO4p",
        "XB1A-1yiEAtx"
      ],
      "authorship_tag": "ABX9TyMdQQcLi98EqXK3Ez0dbKWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EliasKng/BT-Code/blob/master/Chart_2_text_reduced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3mHL9GTjbPL"
      },
      "source": [
        "#Chart-2-text-reduced\n",
        "\n",
        "This notebook will provide the functionality of chart-to-text, however, for single value inputs.\n",
        "\n",
        "So it will do the data-preparation and then put the values into the model and return the summary for the chart.\n",
        "\n",
        "The goal is to provide a function:\n",
        "\n",
        " **createSummary(chartData: ChartData): string**\n",
        "\n",
        "where the returned string is the summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EceSAKtf8Udu"
      },
      "source": [
        "## Startup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B92qnMW1Oqmi"
      },
      "source": [
        "### Installations & Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaLPeoJzSelX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e454ad65-9de3-46db-c2a2-21bc642d5eef"
      },
      "source": [
        "! pip install -U spacy\n",
        "! python3 -m spacy download en_core_web_md\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import nltk\n",
        "import re\n",
        "from typing import List\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.13)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Collecting en-core-web-md==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 45.7 MB 139 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1XNOGTxJO4p"
      },
      "source": [
        "### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9foa_vyJJN_3"
      },
      "source": [
        "def word_tokenize(string: str, language: str = \"english\") -> List[str]:\n",
        "    \"\"\"tokenizes a given string into a list of substrings.\n",
        "\n",
        "    :param string: String to tokenize.\n",
        "    :param language: Language. Either one of ``english'' or ``german''.\n",
        "    \"\"\"\n",
        "    if language not in [\"english\", \"german\"]:\n",
        "        raise ValueError(\"language argument has to be either ``english'' or ``german''\")\n",
        "\n",
        "    # excessive whitespaces\n",
        "    string = re.sub(r\"\\s+\", \" \", string)\n",
        "\n",
        "    # some unicode characters\n",
        "    string = string.replace(\"’\", \"'\")\n",
        "    string = string.replace(\"”\", '\"')\n",
        "    string = string.replace(\"“\", '\"')\n",
        "\n",
        "    # floating point (e.g., 1.3 => 1.3)\n",
        "    string = re.sub(r\"(\\d+)\\.(\\d+)\", r\"\\g<1>._\\g<2>\", string)\n",
        "\n",
        "    # percentage (e.g., below.500 => below .500)\n",
        "    string = re.sub(r\"(\\w+)\\.(\\d+)\", r\"\\g<1> ._\\g<2>\", string)\n",
        "\n",
        "    # end of quote\n",
        "    string = string.replace(\".``\", \". ``\")\n",
        "\n",
        "    # number with apostrophe (e.g. '90)\n",
        "    string = re.sub(r\"\\s'(\\d+)\", r\"' \\g<1>\", string)\n",
        "\n",
        "    # names with Initials (e.g. C. J. Miles)\n",
        "    string = re.sub(r\"(^|\\s)(\\w)\\. (\\w)\\.\", r\"\\g<1>\\g<2>._ \\g<3>._\", string)\n",
        "\n",
        "    # some dots\n",
        "    string = string.replace(\"..\", \" ..\")\n",
        "\n",
        "    # names with apostrophe => expands temporarily\n",
        "    string = re.sub(r\"\\w+'(?!d|s|ll|t|re|ve|\\s)\", r\"\\g<0>_\", string)\n",
        "\n",
        "    # win-loss scores (German notation seems to be XX:YY, but this is also the time format,\n",
        "    # and the times are not tokenized in the original RotoWire. So we manually handle XX:YY\n",
        "    # expression.\n",
        "    string = re.sub(r\"(\\d+)-(\\d+)\", r\"\\g<1> - \\g<2>\", string)\n",
        "\n",
        "    # actual tokenization\n",
        "    tokenized = nltk.word_tokenize(string, language=language)\n",
        "\n",
        "    joined = \" \".join(tokenized)\n",
        "    # shrink expanded name-with-apostrophe expressions\n",
        "    joined = joined.replace(\"'_\", \"'\")\n",
        "    # shrink expanded name-with-initial expressions\n",
        "    joined = joined.replace(\"._\", \".\")\n",
        "    tokenized = joined.split(\" \")\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "def cleanAxisLabel(label):\n",
        "    cleanLabel = re.sub('\\s', '_', label)\n",
        "    cleanLabel = cleanLabel.replace('%', '').replace('*', '')\n",
        "    return cleanLabel\n",
        "  \n",
        "def cleanAxisValue(value):\n",
        "    #print(value)\n",
        "    if value == '-' or value == 'nan':\n",
        "        return '0'\n",
        "    cleanValue = re.sub('\\s', '_', value)\n",
        "    cleanValue = cleanValue.replace('|', '').replace(',', '').replace('%', '').replace('*', '')\n",
        "    return cleanValue\n",
        "\n",
        "def is_number(string):\n",
        "    try:\n",
        "        float(string)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def openMultiColumnData(df):\n",
        "    cols = df.columns\n",
        "    size = df.shape[0]\n",
        "    return cols, size\n",
        "  \n",
        "def getSubject(titleTokens, nerEntities):\n",
        "    fillers = ['in', 'the', 'and', 'or', 'an', 'as', 'can', 'be', 'a', ':', '-',\n",
        "              'to', 'but', 'is', 'of', 'it', 'on', '.', 'at', '(', ')', ',', ';']\n",
        "    entities = {}\n",
        "    entities['Subject'] = []\n",
        "    entities['Date'] = []\n",
        "    # manually find dates, it performs better than using NER\n",
        "    for word in titleTokens:\n",
        "        if word.isnumeric():\n",
        "            if len(word) > 3:\n",
        "                entities['Date'].append(word)\n",
        "        elif word.replace('/', '').isnumeric():\n",
        "            word = word.split('/')[0]\n",
        "            if len(word) > 3:\n",
        "                entities['Date'].append(word)\n",
        "        elif word.replace('-', '').isnumeric():\n",
        "            word = word.split('-')[0]\n",
        "            if len(word) > 3:\n",
        "                entities['Date'].append(word)\n",
        "    # get named entites from title\n",
        "    for X in nerEntities:\n",
        "        if X.label_ == 'GPE' or X.label_ == 'ORG' or X.label_ == 'NORP' or X.label_ == 'LOC':\n",
        "            cleanSubject = [word for word in X.text.split() if word.isalpha() and word not in fillers]\n",
        "            if len(cleanSubject) > 0:\n",
        "                entities['Subject'].append(' '.join(cleanSubject))\n",
        "        if len(entities['Date']) < 1:\n",
        "            if X.label_ == 'DATE':\n",
        "                if X.text.isnumeric():\n",
        "                    entities['Date'].append(X.text)\n",
        "    # guess subject if NER doesn't find one\n",
        "    if len(entities['Subject']) == 0:\n",
        "        uppercaseWords = [word for word in titleTokens if word[0].isupper()]\n",
        "        if len(uppercaseWords) > 1:\n",
        "            guessedSubject = ' '.join(uppercaseWords[1:])\n",
        "        else:\n",
        "            guessedSubject = uppercaseWords[0]\n",
        "        entities['Subject'].append(guessedSubject)\n",
        "    # print(entities['Date'])\n",
        "    cleanTitle = [titleWord for titleWord in titleTokens if titleWord.lower() not in fillers]\n",
        "    return entities, cleanTitle\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpRK-rD676c4"
      },
      "source": [
        "## Cleaning Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB1A-1yiEAtx"
      },
      "source": [
        "### Titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA3MeXhOjXTz"
      },
      "source": [
        "def clean_title(title):\n",
        "  cleanedTitle = word_tokenize(title)\n",
        "  # replace (2009 - 2016) with (2009 to 2016)\n",
        "  lastTokens = cleanedTitle[-3:]\n",
        "  if lastTokens[1] == '-' and lastTokens[0].isnumeric() and lastTokens[2].isnumeric():\n",
        "    cleanedTitle[-2] = 'to'\n",
        "  cleanedTitle = ' '.join(cleanedTitle).replace('*', '')\n",
        "  return cleanedTitle"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7dA-aZzED5b"
      },
      "source": [
        "###Preprocessing\n",
        "- Converts data tables into a sequence of records (taken as input by the model): `data/*split*/trainData.txt`\n",
        "- Cleans summary tokens and substitutes any possible tokens with data variables(e.g., 2018 -> templateValue[0][0]): `data/*split*/trainSummary.txt`\n",
        "- Cleans the title tokens: `data/*split*/trainTitle.txt`\n",
        "- Labels the occurrences of records mentioned within the summary: `data/*split*/trainDataLabel.txt`\n",
        "- Labels the summary tokens which match a record: `data/*split*/trainSummaryLabel.txt`\n",
        "- Saves the gold summaries: `data/*split*/testOriginalSummary.txt`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3mLPlddECyq"
      },
      "source": [
        "def preprocessData(df, title, chartType = 'bar_chart'):\n",
        "  # \"\"\"\n",
        "  # df is an df containing the data\n",
        "  # title is a string which is the cleanedTitle from clean_title()\n",
        "  # chart_type is a string: ('line_chart' | 'bar_chart')\n",
        "  # \"\"\"\n",
        "\n",
        "  # cols = df.columns\n",
        "  # size = df.shape[0]\n",
        "  # cleanCols = [cleanAxisLabel(axis) for axis in cols]\n",
        "  \n",
        "  # dataLine = ''\n",
        "  # colData = []\n",
        "  \n",
        "  # for col in df:\n",
        "  #   vals = df[col].values\n",
        "  #   cleanVals = [cleanAxisValue(str(value)) for value in vals]\n",
        "  #   colData.append(cleanVals)\n",
        "  \n",
        "  # for m in range(0,size):\n",
        "  #   axisTypes = []\n",
        "  #   records = []\n",
        "  #   dataLabels = []\n",
        "  #   for axis, n in zip(cols, range(cols.size)):\n",
        "  #     if is_number(axis[0]):\n",
        "  #       axisTypes.append('numerical')\n",
        "  #     else:\n",
        "  #       axisTypes.append('categorical')\n",
        "  #     value = str(df.at[m, axis])\n",
        "  #     cleanValue = cleanAxisValue(value)\n",
        "  #     record = f\"{cleanCols[n]}|{cleanValue}|{n}|{chartType}\"\n",
        "  #     dataLine += f'{record} '\n",
        "  #     dataLabels.append([0 for item in range(size)])\n",
        "  dataArr = []\n",
        "  dataLabelArr = []\n",
        "  summaryArr = []\n",
        "  summaryLabelArr = []\n",
        "  labelList = []\n",
        "  titleArr = []\n",
        "  oldSummaryArr = []\n",
        "\n",
        "  dataRatioArr = []\n",
        "  captionRatioArr = []\n",
        "\n",
        "  #assert len(captionFiles) == len(dataFiles) == len(titleFiles)\n",
        "  #print(len(captionFiles), len(dataFiles), len(titleFiles))\n",
        "  # may implemented seperately to avoid accidentally ignoring the word rather than month\n",
        "  months = ['january', 'february', 'march', 'april', 'june', 'july', 'august', 'september', 'november', 'december']\n",
        "\n",
        "  years = [str(i) for i in range(1850, 2055)]\n",
        "\n",
        "  fillers = ['in', 'the', 'and', 'or', 'an', 'as', 'can', 'be', 'a', ':', '-',\n",
        "            'to', 'but', 'is', 'of', 'it', 'on', '.', 'at', '(', ')', ',', ';']\n",
        "  \n",
        "  numbers = ['percent', 'percentage', '%', 'hundred', 'thousand', 'million', 'billion', 'trillion',\n",
        "            'hundreds', 'thousands', 'millions', 'billions', 'trillions']\n",
        "  \n",
        "  positiveTrends = ['increased', 'increase', 'increasing', 'grew', 'growing', 'rose', 'rising', 'gained', 'gaining']\n",
        "  negativeTrends = ['decreased', 'decrease', 'decreasing', 'shrank', 'shrinking', 'fell', 'falling', 'dropped',\n",
        "                    'dropping']\n",
        "  \n",
        "  simpleChartTypes = []\n",
        "  complexChartTypes = []\n",
        "\n",
        "  caption = ''\n",
        "  cols, size = openMultiColumnData(df)\n",
        "  complexChartTypes.append(chartType)\n",
        "  cleanCols = [cleanAxisLabel(axis) for axis in cols]\n",
        "  dataLine = ''\n",
        "  summaryLabelLine = \"\"\n",
        "  colData = []\n",
        "  for col in df:\n",
        "      vals = df[col].values\n",
        "      cleanVals = [cleanAxisValue(str(value)) for value in vals]\n",
        "      colData.append(cleanVals)\n",
        "  # iterate through each table row\n",
        "  for m in range(0, size):\n",
        "      axisTypes = []\n",
        "      #rowData = []\n",
        "      records = []\n",
        "      dataLabels = []\n",
        "      for axis, n in zip(cols, range(cols.size)):\n",
        "          if is_number(axis[0]):\n",
        "              axisTypes.append('numerical')\n",
        "          else:\n",
        "              axisTypes.append('categorical')\n",
        "          value = str(df.at[m, axis])\n",
        "          cleanValue = cleanAxisValue(value)\n",
        "          #rowData.append(cleanValue)\n",
        "          record = f\"{cleanCols[n]}|{cleanValue}|{n}|{chartType}\"\n",
        "          print(record)\n",
        "          dataLine += f'{record} '\n",
        "          dataLabels.append([0 for item in range(size)])\n",
        "\n",
        "  return dataLine, title"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snkQce3gD89h"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_XIioIi_eob"
      },
      "source": [
        "testTitles = ['Facebook: number of monthly active users worldwide 2008-2019','National Basketball Association all-time scoring leaders 1946-2020','Instagram accounts with the most followers worldwide 2020']\n",
        "\n",
        "\n",
        "# Import pandas library\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "TESTDATA = StringIO(\"\"\"Country,Average number of children per woman\n",
        "Singapore,1.38\n",
        "Republic of Korea,1.44\n",
        "United Arab Emirates,1.45\n",
        "Puerto Rico,1.45\n",
        "Bosnia and Herzegovina,1.47\n",
        "Saint Lucia,1.48\n",
        "Greece,1.5\n",
        "Cyprus,1.51\n",
        "Italy,1.51\n",
        "Republic of Moldova,1.52\n",
        "\"China, Taiwan Province of China\",1.53\n",
        "Albania,1.53\n",
        "Mauritius,1.54\n",
        "Thailand,1.54\n",
        "Qatar,1.56\n",
        "Nepal,1.56\n",
        "Croatia,1.56\n",
        "Japan,1.57\n",
        "Serbia,1.57\n",
        "Brazil,1.58\n",
        "North Macedonia,1.58\n",
        "Brunei Darussalam,1.59\n",
        "Portugal,1.59\n",
        "Spain,1.59\n",
        "Canada,1.59\n",
        "    \"\"\")\n",
        "\n",
        "df = pd.read_csv(TESTDATA, sep=\",\")\n",
        "  \n",
        "# print dataframe.\n",
        "cleanedTitle = clean_title('Countries with the lowest fertility rate globally 2050-2055')\n",
        "dataline, titleline = preprocessData(df, cleanedTitle)\n",
        "\n",
        "print(dataline, ' ')\n",
        "print(titleline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5spk_IFTs2lH"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    }
  ]
}